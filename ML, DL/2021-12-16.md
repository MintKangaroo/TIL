# 머신러닝의 프로세스

### 지도학습의 흐름
1. 데이터 수집
2. 데이터 클렌징
3. 머신러닝 기법으로 데이터 학습
4. 테스트 데이터로 성능 테스트
5. 머신러닝 모델을 웹 환경 등에서 구현  
'1,2번 과정은 작업 시간의 80%이상의 시간이 소요된다. '  
## 데이터 학습
- 아래의 그래프에서 x축과 y축은 데이터의 특징을 나타낸다.
![screensh](https://upload.wikimedia.org/wikipedia/commons/b/be/Normdist_regression.png)
1. 데이터를 구분하기 위한 적당한 선을 긋는다.
2. 그은 선이 적절한 위치에 있는지 계산하기(선형 회귀(linear regression) - 손실함수(loss function))
3. 선의 위치를 개선하여 수정하기
4. 점들을 적절하게 분류할 수 있는 선을 구하면 끝.

- 컴퓨터가 스스로 답을 찾아가며 데이터의 패턴으로 만든 기준을 모델이라고 한다. 위의 경우에는 적절하게 구해진 선을 모델이라고 할 수 있다.


## 학습을 위해서는 Train 데이터와 Test 데이터를 구분해야한다.
- 훈련 데이터 : 학습에 사용하는 데이터 
- 테스트 데이터  : 학습되 모델의 정밀도 / 정확도를 평가할 사용하는 데이터
'모델을 테스트할 때는 학습에 사용되지 않은 데이터를 이용하여 평가한다.'
#### 대부분의 경우 전체 데이터의 20%정도를 테스트 데이터로 사용하는 경우가 많다.


### 데이터를  분리하기 위한 방법
- 홀드아웃 방법(scikit-learn 라이브러리의 train_test_split함수 이용)  
```
X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=XXX,random_state=0)
```
-> 위의 코드에서 test_size=XXX의 XXX부분에 0.2로 지정하며 20%의 데이터가 테스트 데이터로 이용된다.
- k-분할 교차검증(k-Fold Cross-Validation)
![screensnap](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblbALQ%2FbtqF00tE9Au%2FxXrcTMQglTovz705YlTyb0%2Fimg.png)
: 데이터를 k등분한 후 1/k를 검증 데이터로 나머지 k-1/k를 학습 데이터로 이용한다. 검증 데이터를 이용하여 성능을 평가하고 이 과정을 k번 반복한다. k개의 성능 결과의 평균을 학습 모델의 성능이라고 한다.
```
#sklearn의 cross_validation함수를 이용하여 구현한다.
scores = cross_validation.cross_val_score(svc,X,y,cv=5)
# X : 데이터
# Y : 라벨
# cv = ?
이때 ?에는 k의 값을 입력한다.
```

### 과적합
![screensnap](https://thebook.io/img/080228/165.jpg)
: 컴퓨터가 과하게 학습한 상태를 과적합이라고 한다.  
: 하나의 데이터의 영향을 받아서 올바르게 선을 긋지 못한 상태를 이른다.
#### 과적합을 회피하기 위한 기법
- 드롭아웃 : 학습시 무작위로 일부 뉴런을 없애기 위한 방법이다.
- 정규화 : 편향된 데이터의 영향을 없애는 방법


### 정규화 vs 표준화
- (평균)정규화 : -1과 1 사이에서 값을 가지고 샘플 평균이 0이 되는 샘플로 만드는 과정
![screensnap](https://postfiles.pstatic.net/MjAyMTA3MjJfMTc0/MDAxNjI2ODgzNTcyNTM3.eHpApNCoZy2NSeVSYzUQRC_U5kgNTSorqPquLldqWIcg.gdwHsXc7gT2lSr0pzvh6KCH3zGR0pcWbGCVR79JwyZAg.PNG.sw4r/image.png?type=w773)

- 표준화 : 모든 데이터를 평균이 0이고 분산이 1이 되도록 만드는 것
![screensnap](https://postfiles.pstatic.net/MjAyMTA3MjJfMjEg/MDAxNjI2ODgwNDczODQy.Y-ItEXEFI9roz5h6YupGnypnMKoNmpg6v817VEgBwxcg.DN-clZ8tNPMSJT6-OA81t3Eq7FF1R0PJKsgWFPkCTiwg.PNG.sw4r/image.png?type=w773)
https://blog.naver.com/PostView.naver?blogId=sw4r&logNo=222440340453&parentCategoryNo=&categoryNo=173&viewDate=&isShowPopularPosts=true&from=search


### 앙상블 학습 
: 여러 모델을 학습시킴으로써 데이터의 일반화(특정 사례들의 공통되는 속성들을 일반적인 개념이란 주장으로 공식화 하는 추상화의 한 형태)를 획득하려는 시도
- 배깅 : 복수의 모델을 동시에 학습시켜 예측 결과의 평균을 취하는 것으로 예측 결과의 일반화를 시도한다.
- 부스팅 : 모델의 예측 결과에 대한 모델을 만들어 일반화 성능을 높이는 기술